<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
          content="Distributed Systems, Parallel Programming, Programming Languages and Life">
    <meta name="author" content="Milinda Pathirage">
    <link rel="shortcut icon" href="/images/favicon.png">

    <title>Technology and Life - Recursively Scraping A Blog With Scrapy</title>

    <!-- Google Webfonts -->
    <link href='http://fonts.googleapis.com/css?family=Oswald:300,400,700' rel='stylesheet'
          type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,300italic,400italic,700italic'
          rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400' rel='stylesheet'
          type='text/css'>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- syntax highlighting CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
		
		<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
		<!--[if lt IE 9]>
		  <script src="/js/html5shiv.js"></script>
		  <script src="/js/respond.min.js"></script>
		<![endif]-->
</head>
<body>

<!-- Fixed navbar -->
<div class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">TECHNOLOGY & LIFE</a>
        </div>
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">

            </ul>
            <ul class="nav navbar-nav navbar-right all-caps">
                <li class="active"><a href="/">Home</a></li>
                <li><a href="#about">About</a></li>
                <!--li><a href="#">Photos</a></li>
                <li><a href="#">Archive</a></li-->
            </ul>
        </div>
    </div>
</div>

<div class="container">
    <div class="post">
	<div class="header">
  	<h1>Recursively Scraping A Blog With Scrapy</h1>
  	<p>13 Mar 2012 by Milinda Pathirage</p>
	</div>
	<div class="content">
		<p><a href="http://scrapy.org">Scrapy</a> is a web crawling and scraping framework
written in python. The framework is really simple to understand and easy
to get started with. If you know little bit of Python, you should be
able to build your own web scraper within few minutes. In this post I'm
going to describe how you can use Scrapy to build recursive blog
crawler. Building a recursive scraper using Scrapy is pretty simple, yet
it's getting started guide doesn't help people who are unfamiliar with
the framework to write a recursive scraper.</p>

<p>I'm going to use <a href="http://blog.scrapy.org">blog.scrapy.org</a> as the target
blog and techniques I am discussing will work on other sites as well
with simple changes to information extraction queries. If you are new to
Scrapy it's required to read the <a href="http://doc.scrapy.org/en/latest/intro/tutorial.html">Scrapy tutorial</a> first.
I also assume that you have Scrapy <a href="http://doc.scrapy.org/en/latest/intro/install.html">installed</a> in your machine.</p>

<p>Let's create a Scrapy project first using following command:</p>

<div class="highlight"><pre><code class="bash">scrapy startproject scrapy_sample
</code></pre></div>


<h2>Defining the scrapy item</h2>

<p>Next step is to define the Item which is the container Scrapy spider
used to store the scraped data. I'm going to extract the blog post link,
post title and text content of the post. So my Item definition will look like
following.</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">ScrapySampleItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</code></pre></div>


<h2>Implementing the spider</h2>

<p>Our spider will define initial URL to download content from, how to
follow pagination links and how to extract blog posts in a page and
creating items from the posts.</p>

<p>Your spider class must be a subclass of <a href="http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spider.BaseSpider">scrapy.spider.BaseSpider</a> and
you need to define three main mandatory attributes.</p>

<ul>
<li><strong>name</strong> : Unique identifier for the spider</li>
<li><strong>start_urls</strong> : List of URLs to begin crawling</li>
<li><strong>parse()</strong> : Method which will be called with the downloaded
<a href="http://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Response">Response</a> object for each start URL. Code related to parsing and data
extraction will go under this.</li>
</ul>


<p>Our spider implementation will look like following:</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
<span class="kn">from</span> <span class="nn">scrapy.http.request</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy_sample.items</span> <span class="kn">import</span> <span class="n">ScrapySampleItem</span>

<span class="k">class</span> <span class="nc">ScrapyOrgSpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;scrapy&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;scrapy.org&quot;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://blog.scrapy.org/&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

        <span class="n">next_page</span> <span class="o">=</span>
            <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;//div[@class=&#39;pagination&#39;]/a[@class=&#39;next_page&#39;]/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="ow">not</span> <span class="n">next_page</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

        <span class="n">posts</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;//div[@class=&#39;post&#39;]&quot;</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">post</span> <span class="ow">in</span> <span class="n">posts</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">ScrapySampleItem</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;div[@class=&#39;bodytext&#39;]/h2/a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;div[@class=&#39;bodytext&#39;]/h2/a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&quot;content&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;div[@class=&#39;bodytext&#39;]/p/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">item</span>
</code></pre></div>


<p>First we create <a href="http://doc.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.HtmlXPathSelector">HtmlXpathSelector</a> giving the response object.
This will allow you to select elements in response HTML using <a href="http://www.w3.org/TR/xpath">XPath</a> <a href="http://doc.scrapy.org/en/latest/topics/selectors.html#topics-selectors">selectors</a>. Then we extract the link to the next page of the blog using <strong>"//div[@class='pagination']/a[@class='next_page']/@href"</strong> XPath selector and selector you need to use in your code will depend on the web site you are going to crawl. Once we get the URL of the next page we check whether there are any URLs in the retirned list by selector, because last page will not have a next page link and Scrapy will throw a error when tried to go to empty URL while in the last page of the crawl. Main trick here is we are returning a python generator for the recursive call. You can learn more about reason behind this from this <a href="http://stackoverflow.com/questions/231767/the-python-yield-keyword-explained">stackoverflow conversation</a>. Last thing we are doing inside our parse method is extracting blog posts in the current page and creating list of Scrapy Items for blog posts.</p>

<h2>Running the scraper</h2>

<p>Now you can execute your scraper by  running following command while in
the root directory of your Scrapy project.</p>

<div class="highlight"><pre><code class="bash">scrapy crawl scrapy
</code></pre></div>


<p>Scrapy allows you to save the scraped items into a JSON formatted file.
All you have to do is add <strong>-o filename.json -t json</strong> option to previous
crawl command. This will save the scraped items into a JSON file with
the given name.</p>

<p>You can find more information about Scrapy from <a href="http://doc.scrapy.org/en/latest/index.html#section-basics">here</a>. I strongly recommend you to read the full documentation if you like to dig deeper into Scrapy.</p>

<div class="alert alert-success">
<strong>Source code for the sample can be found <a href="https://github.com/milinda/Scrapy-Sample">here</a>.</strong>
</div>




	</div>
</div>

</div>

<div id="footer">
    <div class="container">
        <div id="about" class="row" style="padding-top:20px;">
            <div class="col-lg-6">
                <p>
                    Milinda Pathirage is a Computer Science PhD student at 
					<a href="http://www.iub.edu/" target="_blank">Indiana University,
                    Bloomington</a>. I am interested in distributed systems, parallel programing
                    and many core architectures. <a href="#">More..</a>
                </p>

                <p style="text-transform: uppercase;">
                    <strong>Find me elsewhere</strong>
                </p>

                <div class="social-profiles">
                    <a href="https://twitter.com/milindalakmal">
                        <img src="/images/twitter-32.png">
                    </a>
                    <a href="https://twitter.com/milindalakmal">
                        <img src="/images/facebook-32.png">
                    </a>
                    <a href="https://twitter.com/milindalakmal">
                        <img src="/images/flickr-32.png">
                    </a>
                    <a href="https://twitter.com/milindalakmal">
                        <img src="/images/linkedin-32.png">
                    </a>
                </div>
            </div>
            <div class="col-lg-6">
                <img src="/images/family.png">
            </div>
        </div>
    </div>
		<script src="/js/jquery.min.js"></script>
		<script src="/js/bootstrap.min.js"></script>
</body>
</html>
